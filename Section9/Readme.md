# 섹션 9: Docker 컨테이너 배포하기
# 개발(Development) 에서 제품 생산(Production) 까지
만약 컨테이너가 없다면 천차만별의 개발 및 프로덕션 환경을 모두 구축할 수 밖에 없다.   
즉, 리모트 호스트 서버에 어플리케이션을 배포하면 로컬 상에서 잘되던 코드가 갑자기 작동하지 않게 되는 것이다.
따라서 개발 환경을 동일하게 가져갈 수 있다는 큰 장점이 있다.     
컨테이너의 **"로컬 머신에서 작동하는 것은 리모트 머신에 배포한 후에도 작동한다"** 라는 것이 도커의 아이디어 배경 사상이다.

컨테이너를 로컬 머신에서 **최종 제품으로 만들 때는 바인드 마운트를 사용하면 안된다**.   
로컬에서 Docker Compose 를 사용하여 모든 것을 테스트할 수 있지만 배포를 위해 다중 서버 또는 다중 호스트 머신에 걸쳐 분할하는 것을 고려할 수 있다.

# 배포 프로세스 & 프로바이더
리모트 서버에 SSH 를 통해 연결하고, 어플리케이에서 개발한 도커 이미지를 도커 허브와 같은 도커 레지스트리로 푸시한 다음 리모트 서버에서 그 이미지를 가져온다.   
그런 다음, 리모트 호스트에 컨테이너를 실행하고 노출해야 하는 모든 포트를 World Wide Web 에 노출한다.

AWS, Azure, Google Cloud 3 가지의 유명한 호스팅 프로바이더가 있다. 

도커화 된 어플리케이션을 실행하기 위해서 준비해야 될 것이 있다.
1. Aws EC2 인스턴스를 생성해야 한다.
2. 필요한 모든 포트를 World Wide Web 에 노출하도록 보안 그룹을 구성해야 한다.
3. Secure Shell 을 의미하는 SSH 를 통해 인스턴스와 연결해야 한다.

# Production 에서 바인드 마운트
## Development 환경
Production 환경에서는 바인드 마운트를 사용하지 않는다.   
그 이유는 바로 개발 모드와 프로덕션 모드 사이에서 컨테이너를 실행하는 것에 차이가 있기 때문이다.    
어플리케이션 작업을 하는 동안에는 컨테이너, 런타임 환경 등을 캡슐화 해야되지만 **코드를 캡슐화 할 필요는 없다**.

개발 환경에서는 로컬의 프로젝트 폴더를 실행 중인 컨테이너 내부의 특정 폴더에 바인딩하여 최신 프로젝트 코드가 항상 컨테이너에 노출되었기에 
코드의 변경사항이 그 컨테이너의 재시작 없이도 즉시 반영될 수 있었다.
이러한 점은 개발 중에 매우 편리하기 때문에 개발 중에 일반적으로 수행하는 작업이다.
즉각적인 업데이트와 이미지를 리빌드하여 컨테이너를 재시작할 필요가 없기 때문이다.

## Production 환경
하지만 Production 환경에서는 이미지와 컨테이너를 취하여, 이를 실행하는 리모트 머신으로 이동한다.
컨테이너는 자립하여 작동하며 리모트 머신의 **주변 설정에 의존하지 않는다**는 것이 도커의 아이디어 사상이다.     
이미지와 그 이미지를 기반으로 하는 컨테이너는 단 하나의 소스이어야 한다고 할 수 있다. 
즉, 이미지를 가져와서 이를 기반으로 **컨테이너를 실행하면 어플리케이션에 필요한 모든 것을 얻을 수 있다는 것**이다.     
컨테이너 안에 우리가 필요한 모든 것들이 담겨져 있어야 한다.    

Production 환경에서는 바인딩 마운트 대신 복사본을 사용한다. 즉, 이미지를 빌드할 때 소스 코드를 이미지에 복사하므로
빌드된 이미지에는 소스 코드와 어플리케이션 환경이 존재한다.
```dockerfile
# ...
COPY . .
```
따라서 바인드 마운트 대신에 ```COPY``` 를 Production 환경에 사용하려는 것이다.

Dockerfile 에 바인드 마운트 설정을 하는 것이 아니라 ```$ docker run``` 명령 실행 시 설정했기 때문에 로컬에서는 바인드 마운트를 사용해도 상관없다.
그렇기에 Development 환경과 Production 환경에 동일한 Dockerfile 을 사용할 수 있다.    
이것이 항상 정확히 동일한 이미지로 작업하고 개발 중에 더 많은 유연성을 갖도록 보장할 수 있는 방법이다.

따라서 컨테이너를 **실행하는 위치에 관계없이 모든 이미지가 주변 설정, 구성이나 코드 없이 실행될 수 있음을 보장**한다.

# AWS & EC2 소개
AWS 를 통해 리모트 머신을 생성할 수 있다. 인스턴스는 사양에 따라 다양하게 선택하여 생성할 수 있다.     
인스턴스 생성 시 키 페어가 제공되는데, 만약 분실한 경우에는 인스턴스를 종료하고, 새 인스턴스를 시작해야 한다.   

그리고 로컬 머신으로 부터 리모트 머신에 연결하기 위한 SSH 프로토콜을 통해 연결한다. 
Mac OS 같은 경우에는 ssh 명령을 내장하기 때문에 SSH 연결을 설정하는데 사용하기 편한다.
```AWS EC2 -> 인스턴스 -> 인스턴스에 연결 -> SSH 클라이언트``` 명령으로 SSH 를 활용해 인스턴스에 연결할 수 있다.

완료된다면 리모트 머신에 도커를 설치하고 컨테이너를 실행시켜야 한다.   

# 가상 머신에 Docker 설치하기
- ```sudo```: root 사용자 권한으로 명령을 실행

리모트 머신에서 ```sudo yum update -y``` 명령을 실행하면 모든 필수 패키지가 업데이트 되고, 최신 버전을 사용하고 있는지 확인할 수 있다.   

그리고 ```sudo amazon-linux-extras install docker``` 명령을 통해 도커를 설치한다. AWS 기반 가상 인스턴스에서는 도커와 같은 부가 소프트웨어를
매우 쉽게 설치할 수 있는 이러한 명령을 사용할 수 있다.

설치가 완료되었다면 ```sudo service docker start``` 명령을 통해 Docker 를 실행할 수 있다.

# 로컬 이미지를 클라우드로 푸시(push) 하기
첫 번째 방법은 프로젝트 폴더의 모든 항목을 리모트 머신에 복사하는 방식이 있다. 그런 다음 거기에서 이미지를 구축한다.
리모트 머신에서 소스 코드를 내려 받고, ```$ docker build``` 명령으로 이미지를 만들고 ```$ docker run``` 으로 실행하는 것이다.   
이 방법은 불필요하고 복잡한 것이 많다.    

두 번째 방법은 로컬 머신에서 미리 이미지를 빌드하는 것이다. 그런 다음, 구축된 이미지를 리모트 머신에 배포하기만 하면 된다.    
로컬에 이미지가 생성되면 리모트 머신에서 ```$ docker run``` 을 실행하기만 하면 된다.
이미지를 로컬에서 빌드한 다음 그 이미지를 Docker Hub 에 푸시하고, 리모트 서버에서 그 이미지를 끌어온 다음 실행할 수 있다.

Docker Hub 에 Repository 를 만들고 로컬의 이미지를 저장한다.    
우선 ```$ docker tag``` 명령을 통해 기존 이미지의 이름을 변경하여 Docker Hub 에 푸시할 수 있다.  
예를 들면 이미지명이 ```node-test``` 이고, docker hub repo 명칭이 ```durumi/docker-test``` 라고 가정해보자.
그렇다면 ```$ docker tag node-test durumi/docker-test``` 명령을 실행하여 ```durumi/docker-test``` 를 새 이름으로 사용할 수 있다.

그리고 ```$ docker push durumi/docker-test``` 명령을 실행하여 도커 Repo 에 이미지를 푸시하면 된다.
만약 로그인이 되지 않아 명령이 실패할 경우 ```$ docker login``` 명령을 통해 도커 로그인을 해야 한다.

# 앱 실행 & 게시하기(EC2 에서)
도커 허브에 이미지를 업로드 했다면 리모트 머신에 해당 이미지로 컨테이너를 실행해야 한다.
```
$ docker run [options] [docker id]/[repository name]
```

* M1 맥북일 경우 build 시 ```--platform linux/amd64``` 명령을 실행해야 Linux 리모트 환경에서 컨테이너 실행이 가능하다.

AWS EC2 의 ```퍼블릭 IPv4 주소```가 리모트 머신의 public IP 주소이다.  
하지만 해당 IP 로 접근하면 연결되지 않는다. 이것은 버그가 아닌 보안 기능이다.
EC2 인스턴스는 Default 로 월드 와이드 웹의 모든 것과 연결이 끊어져 있다. 그리고 보안 그룹으로 제어가 가능하다.

보안 그룹에서는 기본적으로 EC2 인스턴스에 허용되는 트래픽을 제어한다.
아웃바운드 규칙은 다른 곳에 있는 인스턴스 대기열로 부터 허용되는 트래픽을 제어한다. 아웃바운드 규칙으로 EC2 인스턴스와 도커 허브가 통신할 수 있었던 것이다.    
인바운드 규칙은 어딘가에 있는 이 인스턴스의 큐 대기열에 허용된 모든 트래픽이 여기에 표시된다.    
인바운드 규칙에 ```HTTP``` 를 추가해서 월드 와이드 웹에 노출해야 한다.

노출했다면 EC2 의 IP 주소로 접속하면 성공이다.    
굉장한 점은 NodeJS 를 설치할 필요도 없이, 단지 리모트 EC2 인스턴스에 도커만을 설치하고 완성된 이미지를 사용해서 웹 어플리케이션을 실행했다.
리모트 환경에 NodeJS 환경을 설치 및 구성할 필요가 없이 도커와 도커 이미지만 설치하면 된다.     
만약 배포하려는 다중 컨테이너 어플리케이션이 있다면 컴포즈 파일을 가져와 리모트 환경에서 실행할 수도 있다.

# 컨테이너/이미지 관리 & 업데이트
업데이트 된 내용을 리모트 서버로 가져오는 프로세스는 간단하다. 
이미지를 다시 빌드하여 Docker Hub 에 다시 푸시하고, 리모트 서버에서 이 업데이트된 이미지를 사용하도록 하는 것이다.   

기존 동일한 이미지가 로컬에 있을 경우에는 도커는 그것을 사용하기 때문에 도커 허브에서 최신 이미지를 받아오기 위해서는 ```$ docker pull``` 명령을 실행하면 된다.
그리고 해당 이미지를 기반으로 도커 컨테이너를 재실행하면 배포된 코드를 업데이트하는 방법이다.   
즉, 이미지를 리빌드하고, 도커 허브에 푸시한다음, 컨테이너를 다시 실행하기만 하면 된다.

좋은 방법이지만 이것이 도커를 사용하여 어플리케이션을 배포하는 최종적인 방식은 아니다.

# 현재 접근 방식의 단점
```do-it-yourself``` 라는 단점이 있다. 즉, 인스턴스를 수동으로 생성하고, 그것을 수동으로 구성하며, 수동으로 연결하여, 수동으로 도커를 설치했다.   
많은 단계들을 스스로 수행했어야 했다. 

우리가 원하는 것은 자동으로 이미지가 리모트 호스트로 이동하고 그 리모트 호스트는 우리가 스스로 하지 않아도, 자동으로 시스템 소프트웨어가 운영 체제를 업데이트 하도록 관리된다.   
이렇게 된다면 서버, 방확벽, 네트워크 관리에 집중하지 않아도 소스 코드를 작성하고 도커화된 어플리케이션을 구축하는데 집중할 수 있다.
바로 이러한 점을 해결해주는 관리형 서비스가 있다.

# 수동 배포에서 관리형 서비스로
기존 EC2 는 모든 것을 최신 상태로 유지하고, 스스로 모니터링하고, 확장해야 한다. 어플리케이션이 커지고 들어오는 트래픽이 더 많아지면 트래픽을 관리하면서 어플리케이션이
다운되지 않도록 보장해야 한다. 경험이 풍부하고, 클라우드 관련 지식이 많다면 이 방법도 좋은 방법이다.    
하지만 그렇지 않은 경우 불안정하고, 안전하지 않을 수도 있는 설정을 실행할 위험이 있다.

따라서 관리형 서비스, 관리형 리모트 호스트 또는 관리형 리모트 머신이라 부르는 ECS 와 같은 방식도 좋은 방법이다.
이것의 장점은 생성 관리, 업데이트, 모니터링, 스케일링 이 모든 것이 단순화된다는 것이다.
단순히 어플리케이션이나 컨테이너를 배포하려는 경우라면 이러한 관리형 서비스를 사용하는 것이 좋다.

# AWS ECS 를 사용한 배포: 관리형 Docker 컨테이너 서비스
AWS ECS 는 **클러스터, 컨테이너, 테스크, 서비스 4 가지의 범주**가 있다. 

## Container Definition
사용할 컨테이너를 Custom 하여 정의할 수 있는데, ```Image``` 에 도커 허브의 레포지토리 명을 입력하기만 하면 ECS 에서 자동으로 Docker Hub 에서 찾는다.   
만약 다른 컨테이너 저장소(EX. AWS S3) 를 사용하는 경우 해당 URL 을 넣어야 한다.     
하지만 Docker Hub 의 경우에는 저장소 이름만 있으면 된다.

그리고 ```Port mappings``` 은 ```$ docker run``` 명령의 ```-p``` 옵션으로 포트를 노출하는 것과 같은 것이다.

### 고급 옵션
**HEALTHCHECK** 는 컨테이너가 성공적으로 실행 중인지 확인할 수 있도록 하는 AWS 관련 설정이다.     

**ENVIRONMENT** 는 컨테이너가 시작될 때, 이 컨테이너에 대해 실행되어야 하는 Default Entrypoint 또는 명령을 오버라이드 할 수 있다.
이것은 ```$ docker run``` 명령의 ```--workdir``` 옵션과 같은 것이다.
그리고 ```--env``` 옵션으로 환경변수 설정을 한 것을 AWS 콘솔에서 Key-Value 형태로 정의할 수 있다.   

그리고 **CONTAINER TIMEOUTS** 는 이 컨테이너 시작 시도를 중지해야 하는 그 시기를 알려주는 것이다.

**STORAGE AND LOGGING** 은 마운트 지점과 볼륨을 정의할 수 있다. ```-v``` 옵션과 같은 것이다.
**Auto-configure CloudWatch Logs** 옵션을 설정한다면 이 컨테이너에서 생성된 로그를 관리하고 저장한다.

## Task definition
태스크는 기본적으로 어플리케이션의 블루프린트이다. AWS 컨테이너를 시작하는 방법을 알릴 수 있다.
컨테이너를 실행하기 위한 것이 아닌, 이를 실행하는 서버를 구성하는 방법이라 할 수 있다. 
따라서 태스크에는 둘 이상의 컨테이너가 포함될 수 있다.    
즉, 하나의 리모트 머신을 태스크라고 할 수 있다. EC2 인스턴스와 비슷하다고 생각하면 된다.

하지만 ECS 를 통해 직접 관리하는 것이 아닌, 컨테이너를 실행하는 방법과 컨테이너를 위해 어떤 환경을 설정해야 하는지 AWS 에게 알려주고 있다.
그것이 바로 태스크이다.

**FARGATE** 가 Default 로 설정되어 있는데 서버리스라고 부르는 모드에서 구동된다. 
AWS 는 실제로 컨테이너를 실행하는 EC2 인스턴스를 생성하지 않고 대신 컨테이너와 그 실행 설정을 저장한다.
컨테이너가 무언가를 하도록 하는 요청이 있을 때마다 컨테이너를 시작하고, 그 요청을 처리한 다음, 다시 중지시킨다. 
컨테이너가 실행 중인 시간에 대해서만 비용을 지불하고, 유휴 상태에 있는 시간에 대해서는 비용을 지불하지 않기 때문이다.
그리고 FARGATE 를 EC2 로 전환하여 AWS 에 EC2 인스턴스를 생성하도록 하는 것도 가능하다.

## Service
어플리케이션과 그를 포함하는 컨테이너를 실행하는 방법을 컨트롤 한다.
예를 들어 로드 밸런서를 추가할 수 있다. 수신 요청을 Redirection 하고 대기열을 쌓고, 컨테이너를 실행하는 등 백그라운드에서 모든 것을 관리한다.

즉, 모든 태스크는 서비스에 의해 실행된다고 할 수 있다.

## Cluster
우리 서비스가 실행되는 전체 네트워크이다.   
다중 컨테이너 어플리케이션일 경우 하나의 클러스터에 여러 컨테이너를 그룹화 할 수 있다. 
따라서 여러 컨테이너 간에 논리적으로 그룹화되고, 서로 통신할 수 있게 된다.

이제 모든 설정이 끝나고 생성하면 구동되는 어플리케이션을 확인할 수 있다.
```Cluster -> Tasks``` 에서 Task ID 선택하면 Public IP 를 확인할 수 있다.
이 모든 과정에서 큰 장점은 그 어떤 커스텀 서버나 머신을 시작하지 않았다는 것이다.

AWS ECS 는 Auto Scaling 이라고 하는 기능을 제공한다. 그것은 동시에 둘 이상의 실행 중인 컨테이너를 생성한다. 
Task 크기의 확장을 지원하여 들어오는 요청을 처리할 수 있도록 더 많은 컨테이너를 생성하는데 도움이 된다.

# 관리되는 컨테이너를 업데이트 하기
소스코드에 변경된 사항이 있을 경우, Docker image 를 빌드하고, Docker Hub 에 해당 이미지를 올려야 한다.
```
$ docker build ...
$ docker tag ...
$ docker push ...
```

ECS 에서는 도커 허브에 업데이트한 이미지를 자동으로 인식하지는 않는다. 
AWS ECS 의 ```Cluster -> Task -> Task Definition``` 의 실행 중인 태스크를 선택하고 ```Create new revision``` 을 통해 새로운 태스크를 생성한다.
같은 태스크를 다시 만들면 AWS ECS 에서 업데이트된 이미지를 자동으로 가져온다.         
그리고 Actions 에서 Update Service 를 클릭한다. 
- 만약 새로운 태스크를 만들지 않는 다른 방법은 ```Update Service``` 에서 ```Force new Deployment``` 를 선택하는 것이다.

Skip Review 를 클릭한 뒤에 Update Service 를 클릭하면 실제로 최신 이미지를 가져온 다음 이 태스크에서 서비스를 다시 시작한다.

근데 이렇게하면 public IP 가 이전과 다르다. 
AWS 는 구동되는 모든 새 태스크에 대해서 새로운 것을 생성하고 할당한다.
하지만 AWS 에서 할당한 특정 IP 와는 별도로 일반적으로 실행 중인 ECS 태스크에 도메인을 연결하는 방법도 있다.

# 다중 컨테이너 앱 준비하기
AWS ECS 의 경우에 동일한 태스크에 컨테이너를 추가하면 동일한 머신에서의 실행이 보장된다.

# NodeJS 백엔드 컨테이너 구성하기
클러스터 템플릿은 네트워킹 전용으로 선택한다. 그리고 컨테이너명과 VPC 체크해준뒤 Default 로 클러스터를 생성한다.
그렇게하면 AWS 가 클러스터의 모든 컨테이너에 대해 이 클러스터를 프라이빗 클라우드로 설정한다.    
클러스터는 컨테이너의 주변 네트워크일 뿐이다.

클러스터가 생성되었으면 태스크와 서비스를 생성해줘야 한다. 서비스는 태스크를 기반으로 하기 때문에 먼저 태스크를 만들어야 한다.

서버 리스인 Fargate 를 사용하고, 태스크의 역할을 ecsTaskExecutionRole 을 선택한다.
그리고 서버 성능에 맞게 CPU 와 메모리를 선택해야 한다.

그 이후에는 컨테이너를 추가해야 한다. 컨테이너 명과 포트, 이미지 저장소 등을 선택해주고 컨테이너를 추가하면 된다.

# 두 번째 컨테이너 & 로드 밸런서 배포하기
컨테이너 추가 시에 Docker Hub 의 공식 이미지를 추가해도 된다.   

Load balancing, 로그 밸런싱에서 어플리케이션 로드 밸런서를 선택한다.
이것은 들어오는 트래픽이 효율적으로 처리되도록 하지만, 나중에 원할 경우 커스텀 도메인을 할당하는데에도 도움이 된다.
AWS 에서 어플리케이션 로그 밸런서를 만들 때, 서비스 생성 시에 선택한 VPC 와 동일한 VPC 에 연결해야 한다.

Auto Scaling 은 들어오는 트래픽의 급작스러운 증가에 대해 지연 없이 이러한 급증을 처리할 수 있도록
더 많은 동시 컨테이너 인스턴스가 실행되도록 구성한다.

# 안정적인 도메인을 위해 로드 밸런서 사용하기
컨테이너가 배포될 때마다 Public IP 주소는 변경된다. 이것은 일반적이지 않다.
로드 밸런서는 EC2 에 속하며 Fargate 에서도 이를 활용한다.
로드 밸런서의 DNS 을 IP 주소와 같이 사용할 수 있다. 
그렇기에 이제는 IP 주소 변경에 신경 쓰지 않고, **로드밸런서의 DNS name 을 사용하면 되는 것**이다.    
원한다면, 고유한 커스텀 도메인을 해당 로드밸런서 도메인에 매핑할 수도 있다.

<img width="892" alt="스크린샷 2022-07-24 오후 10 55 52" src="https://user-images.githubusercontent.com/63203480/180650439-447b186d-72ed-4379-857d-9b023d58bc2c.png">

Default 로 로드 밸런서는 배포된 서비스의  ```/``` 경로로 요청을 보낸다. 
따라서 Health Check API 가 다른 경로라면 수정해줘야 한다.
```EC2 -> 대상 그룹 -> Target Group -> Health Checks``` 경로에서 수정이 가능하다.

그리고 ```로드밸런서 -> 보안 그룹 편집에서``` 보안 그룹을 Default 외에 보안 그룹을 추가해야 한다.
